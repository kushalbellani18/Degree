{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unable-nevada",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <b> Practical 3</b>\n",
    "    <i> by Kushal Bellani (20162122001) </i>\n",
    "    \n",
    "    You as a data analyst received a task from the project manager. You need to extract insights from different text inputs using NLTK.\n",
    "\n",
    "    steaming words from the list you have received.\n",
    "    find the lemma of a word depending on its meaning and context.\n",
    "    need to use wordNet to find synonyms and antonyms of words.\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "affecting-taxation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat\n",
      "eat\n",
      "eat\n",
      "eat\n"
     ]
    }
   ],
   "source": [
    "# task 1\n",
    "from nltk.stem import PorterStemmer\n",
    "e_words = [\"eat\", \"eating\", \"eats\", \"eats\"]\n",
    "ps = PorterStemmer()\n",
    "\n",
    "for w in e_words:\n",
    "    rootWord = ps.stem(w)\n",
    "    print(rootWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "organic-appendix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: \n",
      "['Eddie', 'walked', 'over', 'to', 'his', 'younger', 'cousins', ',', 'resuming', 'the', 'game', 'they', 'had', 'begun', 'on', 'the', 'plane', '.']\n",
      "\n",
      "\n",
      "Eddie  -->  eddi\n",
      "walked  -->  walk\n",
      "over  -->  over\n",
      "to  -->  to\n",
      "his  -->  hi\n",
      "younger  -->  younger\n",
      "cousins  -->  cousin\n",
      ",  -->  ,\n",
      "resuming  -->  resum\n",
      "the  -->  the\n",
      "game  -->  game\n",
      "they  -->  they\n",
      "had  -->  had\n",
      "begun  -->  begun\n",
      "on  -->  on\n",
      "the  -->  the\n",
      "plane  -->  plane\n",
      ".  -->  .\n"
     ]
    }
   ],
   "source": [
    "# task 1.1\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "sentence = \"Eddie walked over to his younger cousins, resuming the game they had begun on the plane.\"\n",
    "\n",
    "words = word_tokenize(sentence)\n",
    "print(\"Words: \")\n",
    "print(words)\n",
    "print(\"\\n\")\n",
    "\n",
    "ps = PorterStemmer()\n",
    "for word in words:\n",
    "    print(word, \" --> \", ps.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "occupied-finance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming for studies is studi\n",
      "Stemming for studying is studi\n",
      "Stemming for cries is cri\n",
      "Stemming for cry is cri\n"
     ]
    }
   ],
   "source": [
    "# task 2.1\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "text = \"studies studying cries cry\"\n",
    "tokenization = nltk.word_tokenize(text)\n",
    "\n",
    "for w in tokenization:\n",
    "    print(\"Stemming for {} is {}\".format(w, ps.stem(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "independent-economy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma for studies is study\n",
      "Lemma for studying is studying\n",
      "Lemma for cries is cry\n",
      "Lemma for cry is cry\n"
     ]
    }
   ],
   "source": [
    "# task 2.2\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wl = WordNetLemmatizer()\n",
    "text = \"studies studying cries cry\"\n",
    "tokenization = nltk.word_tokenize(text)\n",
    "\n",
    "for w in tokenization:\n",
    "    print(\"Lemma for {} is {}\".format(w, wl.lemmatize(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "honest-india",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('prime.n.01'), Synset('flower.n.03'), Synset('prime.n.03'), Synset('prime.n.04'), Synset('prime.v.01'), Synset('prime.v.02'), Synset('prime.v.03'), Synset('premier.s.01'), Synset('prime.s.02'), Synset('choice.s.01'), Synset('prime.a.04'), Synset('prime.s.05')]\n"
     ]
    }
   ],
   "source": [
    "# task 3.1\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "syns = wordnet.synsets(\"prime\")\n",
    "print(syns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "instructional-malpractice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active: \n",
      "{'combat-ready', 'active', 'active_agent', 'dynamic', 'alive', 'participating', 'fighting', 'active_voice'}\n",
      "\n",
      "{'inactive', 'extinct', 'passive', 'stative', 'dormant', 'passive_voice', 'quiet'}\n",
      "\n",
      "\n",
      "Good: \n",
      "{'beneficial', 'dependable', 'dear', 'unspoiled', 'honorable', 'practiced', 'secure', 'in_effect', 'safe', 'in_force', 'skilful', 'good', 'unspoilt', 'estimable', 'respectable', 'commodity', 'upright', 'right', 'near', 'trade_good', 'ripe', 'goodness', 'just', 'well', 'serious', 'adept', 'sound', 'undecomposed', 'salutary', 'expert', 'effective', 'skillful', 'full', 'honest', 'proficient', 'soundly', 'thoroughly'}\n",
      "\n",
      "{'evil', 'badness', 'ill', 'bad', 'evilness'}\n",
      "\n",
      "\n",
      "Sad: \n",
      "{'pitiful', 'sorry', 'lamentable', 'deplorable', 'distressing', 'sad'}\n",
      "\n",
      "{'glad'}\n",
      "\n",
      "\n",
      "Anxious: \n",
      "{'anxious', 'nervous', 'dying', 'uneasy', 'queasy', 'unquiet'}\n",
      "\n",
      "set()\n",
      "\n",
      "\n",
      "Success: \n",
      "{'succeeder', 'winner', 'success', 'achiever'}\n",
      "\n",
      "{'failure', 'loser'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# task 3.2\n",
    "from nltk.corpus import wordnet\n",
    "synonyms = []\n",
    "antonyms = []\n",
    "\n",
    "for syn in wordnet.synsets(\"Active\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "\n",
    "print(\"Active: \")\n",
    "print(set(synonyms))\n",
    "print(\"\")\n",
    "print(set(antonyms))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "synonyms = []\n",
    "antonyms = []\n",
    "\n",
    "for syn in wordnet.synsets(\"Good\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "            \n",
    "print(\"Good: \")\n",
    "print(set(synonyms))\n",
    "print(\"\")\n",
    "print(set(antonyms))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "synonyms = []\n",
    "antonyms = []\n",
    "\n",
    "for syn in wordnet.synsets(\"Sad\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "            \n",
    "print(\"Sad: \")\n",
    "print(set(synonyms))\n",
    "print(\"\")\n",
    "print(set(antonyms))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "synonyms = []\n",
    "antonyms = []\n",
    "\n",
    "for syn in wordnet.synsets(\"Anxious\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "            \n",
    "print(\"Anxious: \")\n",
    "print(set(synonyms))\n",
    "print(\"\")\n",
    "print(set(antonyms))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "synonyms = []\n",
    "antonyms = []\n",
    "\n",
    "for syn in wordnet.synsets(\"Success\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "            \n",
    "print(\"Success: \")\n",
    "print(set(synonyms))\n",
    "print(\"\")\n",
    "print(set(antonyms))\n",
    "print(\"\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-miami",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
